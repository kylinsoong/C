= Networking the Big-IP
:toc: manual

== Routed Mode 

[source, bash]
.*1. Set up Routed mode - create http pool, http vs*
----
tmsh create ltm pool http_pool members add { 10.1.20.11:8081 { address 10.1.20.11 } 10.1.20.12:8081 { address 10.1.20.12 } }
tmsh create ltm virtual http_vs destination 10.1.10.20:80 pool http_pool
----

[source, bash]
.*2. How Routed Mode Works*
----
$ curl -i http://10.1.10.20/hello
HTTP/1.1 200 OK
Date: Thu, 06 Feb 2020 22:17:52 GMT
Server: Apache/2.4.7 (Ubuntu) PHP/5.5.9-1ubuntu4.12 OpenSSL/1.0.1f
Last-Modified: Sat, 01 Feb 2020 18:50:10 GMT
ETag: "c-59d8828df3517"
Accept-Ranges: bytes
Content-Length: 12
Connection: close

Hello World
----

*3. Packes Flow*

image:img/routed-mode-flow.png[]

[source, txt]
.*4. Catch the dump*
----
tcpdump -ni external host 10.1.10.20
----

[source, bash]
.*5. check the tcp status from backend server*
----
$ netstat -antulop | grep 8081
----

[source, bash]
.*6. Check the backend server gateway*
----
$ ip route | grep default
default via 10.1.20.240 dev eth1  proto static
----

[source, bash]
.*7. Clean up*
----
tmsh delete ltm virtual http_vs
tmsh delete ltm pool http_pool 
----

== SNAT & NAT

=== NAT

image:img/snat-nat.png[]

如上图，客户端想直接访问 BIG-IP 保护的内部网络上节点10.1.20.13（BIG-IP 网络可以配置内网和外网，外网和 internet 互联，内网是私有地址）,

* NAT 可以在 BIG-IP 外网端配置一个和内网地址的映射，就可以允许 Client 端访问 10.1.20.13 上所有的服务
* NAT 是双向的，内部网节点也可以访问 Client 端的服务。

[source, bash]
.*1. Create NAT mapping*
----
tmsh create ltm nat custom_nat originating-address 10.1.20.13 translation-address 10.1.10.200
----

[source, bash]
.*2. tcpdump monitor external interface and host*
----
tcpdump -ni external host 10.1.10.200
----

[source, bash]
.*3. Access the web server*
----
curl -i http://10.1.10.200/hello
----

[source, bash]
.*4. Clean up*
----
tmsh delete ltm nat custom_nat 
----

=== SNAT

和 NAT 不同，SNAT 没有监听客户端的请求，不是将内部私有地址映射为公有地址，而是将公有地址段映射为一个内部地址。

image:img/snat-snat.png[] 

如上示例中 VS 监听 10.1.10.20:80，Client 访问 http://10.1.10.20，10.1.20.13 最终接收到请求，而在 10.1.20.13 上查看：

* Client IP address/port: *10.1.20.201:61867*
* Pool member address/port: *10.1.20.13:80*
* Virtual server address: *10.1.10.20*

如上 Client 访问 http://10.1.10.20 并返回结果的具体过程：

1. Client 发送请求到 VS （SRC：74.120.252.18:56342，DEST: 10.1.10.20:80）
2. BIG-IP 接收到请求后修改 SRC 地址为 SNAT 地址 10.1.20.210，DEST 地址为 pool member 地址(10.1.20.13)
3. pool member 发送返回请求到 BIG-IP（SRC：10.1.20.13，DEST: 10.1.20.210）
4. BIG-IP 修改 SRC 为 VS 地址 10.1.10.20，DEST 地址为 74.120.252.18

[source, bash]
.*1. Setup*
----
tmsh create ltm pool http_pool members add { 10.1.20.11:8081 { address 10.1.20.11 } 10.1.20.12:8081 { address 10.1.20.12 } }
tmsh create ltm virtual http_vs destination 10.1.10.20:80 pool http_pool
tmsh create ltm snat custom_snat origins add { 10.1.10.0/24 } translation 10.1.20.201
----

[source, bash]
.*2. tcpdump monitor interfaces*
----
tcpdump -ni internal host 10.1.20.201
tcpdump -ni external host 10.1.10.20
----

[source, bash]
.*3. access the app*
----
curl http://10.1.10.20/hello
----

[source, bash]
.*4. Clean up*
----
tmsh delete ltm virtual http_vs 
tmsh delete ltm pool http_pool 
tmsh delete ltm snat custom_snat 
----

=== SNAT Pool

与 SNAT 原理一致，SNAT Pool 里可包括多个 Translation 地址，SNAT Pool 主要解决的问题是支持最大连接数的问题，一个 IP 地址，最多可对应 65535 个端口，如果并发超过了这个值，则会造成阻塞，如果多个 Translation 地址则在几何倍数上增加了最大连接数，一定程度上解决了此问题。

[source, bash]
.*1. Set up*
----
tmsh create ltm snatpool custom_snatpool members add { 10.1.20.222 10.1.20.223 10.1.20.224 } 
tmsh create ltm pool http_pool members add { 10.1.20.11:8081 { address 10.1.20.11 } 10.1.20.12:8081 { address 10.1.20.12 } }
tmsh create ltm virtual http_vs destination 10.1.10.20:80 pool http_pool source-address-translation { pool custom_snatpool type snat } 
----

[source, bash]
.*2. tcpdump monitor interfaces*
----
tcpdump -ni internal host 10.1.20.11 or 10.1.20.12
tcpdump -ni external host 10.1.10.20
----

[source, bash]
.*3. access the app*
----
curl http://10.1.10.20/hello
----

[source, bash]
.*4. Check the collected info*
----
// 1. external inerface
# tcpdump -ni external host 10.1.10.20
00:27:55.281949 IP 10.1.10.1.60949 > 10.1.10.20.http: Flags [SEW], seq 4061332314, win 65535, options [mss 1460,nop,wscale 6,nop,nop,TS val 1281255222 ecr 0,sackOK,eol], length 0 in slot1/tmm1 lis=

// 2. internal interface
# tcpdump -ni internal host 10.1.20.11 or 10.1.20.12
00:27:55.281989 IP 10.1.20.222.19175 > 10.1.20.11.tproxy: Flags [SEW], seq 4061332314, win 65535, options [mss 1460,nop,wscale 6,nop,nop,TS val 1281255222 ecr 0,sackOK,eol], length 0 out slot1/tmm1 lis=/Common/http_vs

// 3. the TCP TIME_WAIT from app server
$ netstat -antulop | grep 8081
tcp6       0      0 10.1.20.11:8081         10.1.20.222:19175       TIME_WAIT   -                timewait (58.15/0/0)
----

[source, bash]
.*5. Clean up *
----
tmsh delete ltm virtual http_vs
tmsh delete ltm pool http_pool
tmsh delete ltm snatpool custom_snatpool
----

=== 内外访问外网

SNAT 可以配置内网访问外网，如果内网访问外网，则将 origins 配置为内网网段，将 translation 配置为外网地址.

[source, bash]
.*1. Setup*
----
tmsh create ltm snat internet_access origins add { 10.1.20.0/24 } translation 10.1.10.100
----

[source, bash]
.*2. Test access external http service*
----
curl http://10.1.10.20/
----

[source, bash]
.*3. Clean up*
----
tmsh delete ltm snat internet_access
----

== 用例

[cols="2,5a"]
|===
|Name |Description

|SSH 到内网
|需要在外部网络穿透 SSH 连接到内部某台服务器

[source, bash]
----
// create nat
create ltm nat ssh_nat originating-address 10.1.20.14 translation-address 10.1.10.100 

// ssh
ssh root@10.1.10.100

// clean up
delete ltm nat ssh_nat 
----

|===

== 组网架构

=== 负载均衡设备组网有什么特殊之处

负载均衡设备属于网络设备，处于应用的入口，负责将网络负载分发到不同的应用，那么负载均衡设备组网和传统网络设备有什么不同？传统网络设备如路由器负责 OSI 3 层基于 IP 的转发，交换机设备负责 OSI 2 层基于链路或广播域的转发，分工明确，在传统的网络设计中，基本上都是按照交换和路由的原理来进行设计的。

在交换和路由的设计中，一个非常关键点就是都是基于数据包来进行转发的。在基于包交换的结构中，由于不用考虑连接，因此数据流量可以采用不对称的流向方式，比如在 OSPF、BGP 的环境下，同一个连接的往返数据包，甚至一个方向的数据包都可能通 过不同的链路进行传输。而所有控制数据包流向的依据都是按照 IP 包头中所包含的源 IP 地 址和目的 IP 地址进行转发。在这种情况下，完全不需要考虑连接的完整性。

而负载均衡设备是将网络负载转发向应用，所有的转发原则都是基于 OSI 4 层以上的信息来进行转发。最基本的就是按照连接来进行处理的。因此，在进行网络设计的时候，和传统的网络结构有所不同。在应用负载均衡的网络架构中，所有的处理都至少是基于四层信息，也就是除了源 IP 地址和目的地址之外，还要有源端口和目的端口参与转发判断。这样，就和 NAT 等基础处 理一样，同一个 connection 的往返数据流通常是需要都通过同一台设备。这样，在每台负载均衡设备上都能看到完整的数据流。另外，在进行一些七层处理的时候，数据流的往返通过同一 台设备也是属于必要条件之一。


=== 单臂接入模式

单臂模式是一种古老的接入模式，最初单臂模式的出现是因为负载均衡的性能不足造成的。在四层负载均衡出现的初期，所有的设备都是基于服务器结构的。四层负载均衡基本上是通过安装在服务器上的软件处理，在早期的 CPU 处理能力不足的情况下，负责均衡无法提供高带宽的吞吐能力，因此采用负载均衡只是提供用户请求的分配，而让真实服务器的回应都通过二/三层交换机直接回应给客户端。在大部分的 应用情况下，服务器的回应数据流量要远远大于客户的请求数据流量，因此，在这种情况下， 可以通过性能较差的负载均衡处理非常大的网络吞吐。

单臂模式为典型的基于服务器架构的负载均衡部署架构这些设备都提供较少的端口(2-6 个)。而采用单臂接入模式可以节省对负载均衡的端口使用量。因此， 在此类设备的部署结构中，会主要采用单臂模式接入。如下图，单臂接入模式下的网络结构，所谓单臂模式，就是指在上只配置一个 Vlan，使用一个端口(或者 Trunk 端 口)连接到网络中，所有的处理均在这一个 Vlan 中进行。

image:img/ltm-single-vlan.png[]

一句话总结，单笔模式，同一 VLAN，只处理请求，不处理返回。

如下图为单臂源地址替换接入典型主备高可用架构架构设计，

image:img/ltm-single-vlan-cluster.png[]

1. 两台设备互为主备，主备之间有两条链路，分别进行网络同步和串口心跳
2. 负载均衡设备和核心交换之间通过 Trunk 聚合链路
3. 负载均衡设备和服务器处于同一个 VLAN，网关均为核心交换设备 

在单臂接入的网络结构下，存在以下几种组网架构：

1. 源地址替换模式
2. npath 模式
3. 服务器非直连模式
4. 服务器更改网关模式

NOTE: 单臂模式下如果客户端、服务器、负载均衡在同一个 vlan，则需要在负载均衡上配置 SNAT 以确保正常工作。

==== 源地址替换模式

如下图为源地址替换模式数据访问流程示意，源地址替换模式是对已经上线系统结构变化最小的一种，在源地址替换模式下的设计要点主要有以下几点:

1. 负载均衡只需要配置一个 Vlan，一个 interface 地址，虚拟服务的地址和服务器在同一个网段上。
2. 在负载均衡上配置源地址 SNAT，使用户请求在发往服务器的时候，源地址均被替换为负载均衡的源地址(如果不配置 SNAT，会出现服务器端的返回通过网关直接返回给客户端，客户端接收到的响应数据包的源地址和客户端发送数据包中的目的地址不匹配，导致客户端请求失败)。
3. 所有服务器看到的数据请求的源地址均为负载均衡的源地址，而不是真正的客户端地址。

image:img/ltm-single-lan-source-replace.png[]


源地址替换模式的数据流处理流程如下:

1. 客户端发送请求到负载均衡上的虚拟服务器，此时发送数据包（Source IP: 192.168.0.1，Source Port: 6787，Destination IP: 192.168.1.1，Destination Port: 80）的目的 IP 和端口为负载均衡上虚拟服务器监听的 IP 和端口；
2. 核心交换机将请求转发到负载均衡上的虚拟服务器，虚拟服务器对接收到的数据包进行修改，替换源 IP 为负载均衡设备上的 SNAT 地址 192.168.1.253，源端口替换为一个随机的源端口，同时修改目的地址和目的端口为服务器的 IP 地址 192.168.1.11 和应用侦听端口 80
3. 负载均衡将请求转发给服务器，此时数据包的基本信息如下: Source IP: 192.168.1.253，Source Port: 8888，Destination IP: 192.168.1.11，Destination Port: 80
4. 服务器处理完请求后将结果返回给负载均衡。此时数据包的基本信息如下: Source IP: 192.168.1.11 ，Source Port: 80，Destination IP: 192.168.1.253，Destination Port: 8888。负载均衡接收到数据包后对数据包进行修改，源IP为 192.168.1.1，源端口为 8888，目的地IP 为 192.168.0.1，目的地端口为 6768
5. 负载均衡将数据包返回给核心交换设备，此时数据包的基本信息如下: Source IP: 192.168.1.1，Source Port: 80，Destination IP: 192.168.0.1，Destination Port: 6768
6. 核心交换设备将数据包返回给客户端

NOTE: 这种架构的缺点是服务器不知道客户端的地址，这对一些审计或统计性要求统计客户端 IP 的系统来说会存在问题，只有在 HTTP 协议的时候，可以通过将源地址插入到客户端请求的 HTTP Header 里，然后在服务器上通过读取这个Header，获得客户端的真实源IP地址。

==== npath 模式

如下为 npath 模式的组网架构示意。npath 模式设计的关键：

1. 在服务器上配置 loopback 地址，这个 loopback 地址的 IP 和端口与负载均衡上的虚拟服务器监听的 IP 和端口一致
2. 负载均衡接收到客户端请求后不对源和目的地的 IP 和端口做任何修改，只通过修改目的地 MAC 地址将请求转发给服务器
3. 服务器上的返回不经过负载均衡直接通过自身网关返回给客户端

image:img/ltm-single-vlan-npath.png[]

npath 模式数据访问流程:

1. 客户端发送请求到负载均衡上的虚拟服务器，此时发送数据包（Source IP: 192.168.0.1，Source Port: 6787，Destination IP: 192.168.1.1，Destination Port: 80）的目的 IP 和端口为负载均衡上虚拟服务器监听的 IP 和端口；
2. 核心交换机将请求转发到负载均衡上的虚拟服务器，虚拟服务器对接收到的数据包中源和目的地的 IP 和端口不做任何改变，只对 IP Packet 中的目的地 MAC 地址修改为服务器的 MAC 地址；
3. 负载均衡将请求转发给服务器，此时发送数据包（Source IP: 192.168.0.1，Source Port: 6787，Destination IP: 192.168.1.1，Destination Port: 80）和步骤 1 中的数据包相比没有任何变化；
4. 服务器接收到数据包后发现发现请求是发往 Loopback 地址和服务端口，于是将请求提交到 Loopback 地址上的应用侦听端口，在服务器应用端处理完成后，将数据包的源和目的和客户端的请求进行反转，此时数据包变成了（Source IP: 192.168.1.1 Source Port: 80 Desitnation IP: 192.168.0.1 Destination Port: 6787），数据包不返回给负载均衡，通过服务器默认的网关返回给客户端。
5. 客户端接收到了服务器的返回

NOTE: npath 模式最大的优势是负载均衡只处理客户端的请求，服务器的响应不经过负载均衡，通常 HTTP 请求带来的网络负载远远小于服务器响应带来的网络负载（上传和下载的比例可以超过 1 比 10），所以 npath 模式下负载均衡整体处理能力将提高很多，较小规格的负载均衡会处理较大网络负载。npath 模式的缺点是必须在服务器上配置 LoopBack 地址，这带来了额外的运维和后期维护的成本。

==== 服务器非直连模式

如下为服务器非直连模式组网示意，这种组网架构主要解决的问题是负载均衡和服务器不在同一个 VLAN 的场景，设计的关键是：

1. 负载均衡上不需要对客户端请求的源地址进行替换
2. 需要在核心交换设备上进行相应的 VLAN 配置配置，及相应源地址路由配置，将服务器的所有返回数据包转向LTM，这样才能保证进出的连接完整性

image:img/ltm-single-vlan-nodirect.png[]

服务器非直连模式数据访问流程:

1. 客户端发送请求到负载均衡上的虚拟服务器，此时发送数据包（Source IP: 192.168.0.1 Source Port: 6787 Destination IP: 192.168.1.1 Destination Port: 80）的目的 IP 和端口为负载均衡上虚拟服务器监听的 IP 和端口；
2. 核心交换机将请求转发到负载均衡上的虚拟服务器，虚拟服务器对接收到的数据包中源地的 IP 和端口不做任何改变，对目的地址的 IP 和端口改为服务器的 IP 和目的端口
3. 负载均衡将请求通过 vlan 网关转发给核心交换设备
4. 核心交换设备将请求发送给服务器，此时发送数据包（Source IP: 192.168.0.1 Source Port: 6787 Destination IP: 192.168.2.11 Destination Port: 80）中的目的地址为服务器服务监听的 IP 和目的端口
5. 服务器处理结束后交换源和目的地址，此时数据包(Source IP: 192.168.2.11 Source Port: 80 Destination IP: 192.168.0.1 Destination Port: 6787)，将结果返回给核心交换设备
6. 核心交换设备进行源地址路由，将服务器的所有返回数据包转向负载均衡，负载均衡收到数据包后替换源 IP 和端口为负载均衡上虚拟服务器的 IP 和端口
7. 负载均衡将数据包(Source IP: 192.168.1.1 Source Port: 80 Destination IP: 192.168.0.1 Destination Port: 6787) 通过 vlan 网关返回给核心交换设备
8. 客户端接收到了服务器的返回

NOTE: 服务器非直连模式最大的优势在于负载均衡上不需要配置 SNAT，缺点在于网络结构负载，带来额外运维和维护成本。

==== 服务器更改网关模式

和源地址替换模式组网架构类似，服务器更改网关模式需要修改服务器网关，指向负载均衡网关 Self IP，这样就避免了在负载均衡上配置 SNAT，服务器端可以知道客户端的地址（源地址替换模式下最大的缺陷）。服务器更改网关模式组网架构如下：

image:img/ltm-single-vlan-gateway.png[]

服务器更改网关模式模式组网的关键点：

1. 负载均衡不需要配置 SNAT，核心交换设备中只需配置一个 vlan，相应配置简单
2. 服务器上需要修改默认网关指向负载均衡的 Self IP

服务器更改网关的访问流程如下:

1. 客户端发送请求到负载均衡上的虚拟服务器，此时发送数据包（Source IP: 192.168.0.1，Source Port: 6787，Destination IP: 192.168.1.1，Destination Port: 80）的目的 IP 和端口为负载均衡上虚拟服务器监听的 IP 和端口；
2. 核心交换机将请求转发到负载均衡上的虚拟服务器，虚拟服务器对接收到的数据包进行修改，将目的 IP 和端口修改为服务器 IP（192.168.1。11） 和端口（80）
3. 负载均衡将请求转发给服务器，此时发送数据包（Source IP: 192.168.0.1，Source Port: 6787，Destination IP: 192.168.1.11，Destination Port: 80）
4. 服务器处理结束后交换源和目的地址，此时数据包(Source IP: 192.168.1.11 Source Port: 80 Destination IP: 192.168.0.1 Destination Port: 6787)，将结果根据网关返回给负载均衡，负载均衡对数据包中源 IP 修改为虚拟服务器 IP，源端口修改为虚拟服务器端口
5. 负载均衡将数据包返回给核心交换机，此时数据包(Source IP: 192.168.1.1 Source Port: 80 Destination IP: 192.168.0.1 Destination Port: 6787)
6. 客户端接收到了服务器的返回

NOTE: 服务器更改网关模式最大的优点服务器可以看到客户端的源 IP 地址，负载均衡上不需要配置 SNAT，对网络的修改比较小；缺点是由于更改了服务器的网关，因此， 在实际的应用环境中，会遇到新的问题就是服务器的管理问题，fastl4 profile 中有参数可以允许只有 SYN 的 TCP 连接。

=== 双臂接入模式

双臂接入模式是现在比较推荐的模式，之所以承做双臂模式是因为在负载均衡内配置有两个不同的 vlan 将业务的入口和后台服务器隔开。下图为双臂接入模式典型架构设计：

image:img/ltm-w-vlan-arch.png[]

负载均衡采用主-备工作模式的冗余切换架构，两台设备之间通过 ARP 广播来实现主备设备的控制。

=== 远程节点模式


