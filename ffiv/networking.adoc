= Networking the Big-IP
:toc: manual

== Routed Mode 

[source, bash]
.*1. Set up Routed mode - create http pool, http vs*
----
tmsh create ltm pool http_pool members add { 10.1.20.11:8081 { address 10.1.20.11 } 10.1.20.12:8081 { address 10.1.20.12 } }
tmsh create ltm virtual http_vs destination 10.1.10.20:80 pool http_pool
----

[source, bash]
.*2. How Routed Mode Works*
----
$ curl -i http://10.1.10.20/hello
HTTP/1.1 200 OK
Date: Thu, 06 Feb 2020 22:17:52 GMT
Server: Apache/2.4.7 (Ubuntu) PHP/5.5.9-1ubuntu4.12 OpenSSL/1.0.1f
Last-Modified: Sat, 01 Feb 2020 18:50:10 GMT
ETag: "c-59d8828df3517"
Accept-Ranges: bytes
Content-Length: 12
Connection: close

Hello World
----

*3. Packes Flow*

image:img/routed-mode-flow.png[]

[source, txt]
.*4. Catch the dump*
----
tcpdump -ni external host 10.1.10.20
----

[source, bash]
.*5. check the tcp status from backend server*
----
$ netstat -antulop | grep 8081
----

[source, bash]
.*6. Check the backend server gateway*
----
$ ip route | grep default
default via 10.1.20.240 dev eth1  proto static
----

[source, bash]
.*7. Clean up*
----
tmsh delete ltm virtual http_vs
tmsh delete ltm pool http_pool 
----

== SNAT & NAT

=== NAT

image:img/snat-nat.png[]

如上图，客户端想直接访问 BIG-IP 保护的内部网络上节点10.1.20.13（BIG-IP 网络可以配置内网和外网，外网和 internet 互联，内网是私有地址）,

* NAT 可以在 BIG-IP 外网端配置一个和内网地址的映射，就可以允许 Client 端访问 10.1.20.13 上所有的服务
* NAT 是双向的，内部网节点也可以访问 Client 端的服务。

[source, bash]
.*1. Create NAT mapping*
----
tmsh create ltm nat custom_nat originating-address 10.1.20.13 translation-address 10.1.10.200
----

[source, bash]
.*2. tcpdump monitor external interface and host*
----
tcpdump -ni external host 10.1.10.200
----

[source, bash]
.*3. Access the web server*
----
curl -i http://10.1.10.200/hello
----

[source, bash]
.*4. Clean up*
----
tmsh delete ltm nat custom_nat 
----

=== SNAT

和 NAT 不同，SNAT 没有监听客户端的请求，不是将内部私有地址映射为公有地址，而是将公有地址段映射为一个内部地址。

image:img/snat-snat.png[] 

如上示例中 VS 监听 10.1.10.20:80，Client 访问 http://10.1.10.20，10.1.20.13 最终接收到请求，而在 10.1.20.13 上查看：

* Client IP address/port: *10.1.20.201:61867*
* Pool member address/port: *10.1.20.13:80*
* Virtual server address: *10.1.10.20*

如上 Client 访问 http://10.1.10.20 并返回结果的具体过程：

1. Client 发送请求到 VS （SRC：74.120.252.18:56342，DEST: 10.1.10.20:80）
2. BIG-IP 接收到请求后修改 SRC 地址为 SNAT 地址 10.1.20.210，DEST 地址为 pool member 地址(10.1.20.13)
3. pool member 发送返回请求到 BIG-IP（SRC：10.1.20.13，DEST: 10.1.20.210）
4. BIG-IP 修改 SRC 为 VS 地址 10.1.10.20，DEST 地址为 74.120.252.18

[source, bash]
.*1. Setup*
----
tmsh create ltm pool http_pool members add { 10.1.20.11:8081 { address 10.1.20.11 } 10.1.20.12:8081 { address 10.1.20.12 } }
tmsh create ltm virtual http_vs destination 10.1.10.20:80 pool http_pool
tmsh create ltm snat custom_snat origins add { 10.1.10.0/24 } translation 10.1.20.201
----

[source, bash]
.*2. tcpdump monitor interfaces*
----
tcpdump -ni internal host 10.1.20.201
tcpdump -ni external host 10.1.10.20
----

[source, bash]
.*3. access the app*
----
curl http://10.1.10.20/hello
----

[source, bash]
.*4. Clean up*
----
tmsh delete ltm virtual http_vs 
tmsh delete ltm pool http_pool 
tmsh delete ltm snat custom_snat 
----

=== SNAT Pool

与 SNAT 原理一致，SNAT Pool 里可包括多个 Translation 地址，SNAT Pool 主要解决的问题是支持最大连接数的问题，一个 IP 地址，最多可对应 65535 个端口，如果并发超过了这个值，则会造成阻塞，如果多个 Translation 地址则在几何倍数上增加了最大连接数，一定程度上解决了此问题。

[source, bash]
.*1. Set up*
----
tmsh create ltm snatpool custom_snatpool members add { 10.1.20.222 10.1.20.223 10.1.20.224 } 
tmsh create ltm pool http_pool members add { 10.1.20.11:8081 { address 10.1.20.11 } 10.1.20.12:8081 { address 10.1.20.12 } }
tmsh create ltm virtual http_vs destination 10.1.10.20:80 pool http_pool source-address-translation { pool custom_snatpool type snat } 
----

[source, bash]
.*2. tcpdump monitor interfaces*
----
tcpdump -ni internal host 10.1.20.11 or 10.1.20.12
tcpdump -ni external host 10.1.10.20
----

[source, bash]
.*3. access the app*
----
curl http://10.1.10.20/hello
----

[source, bash]
.*4. Check the collected info*
----
// 1. external inerface
# tcpdump -ni external host 10.1.10.20
00:27:55.281949 IP 10.1.10.1.60949 > 10.1.10.20.http: Flags [SEW], seq 4061332314, win 65535, options [mss 1460,nop,wscale 6,nop,nop,TS val 1281255222 ecr 0,sackOK,eol], length 0 in slot1/tmm1 lis=

// 2. internal interface
# tcpdump -ni internal host 10.1.20.11 or 10.1.20.12
00:27:55.281989 IP 10.1.20.222.19175 > 10.1.20.11.tproxy: Flags [SEW], seq 4061332314, win 65535, options [mss 1460,nop,wscale 6,nop,nop,TS val 1281255222 ecr 0,sackOK,eol], length 0 out slot1/tmm1 lis=/Common/http_vs

// 3. the TCP TIME_WAIT from app server
$ netstat -antulop | grep 8081
tcp6       0      0 10.1.20.11:8081         10.1.20.222:19175       TIME_WAIT   -                timewait (58.15/0/0)
----

[source, bash]
.*5. Clean up *
----
tmsh delete ltm virtual http_vs
tmsh delete ltm pool http_pool
tmsh delete ltm snatpool custom_snatpool
----

=== 内外访问外网

SNAT 可以配置内网访问外网，如果内网访问外网，则将 origins 配置为内网网段，将 translation 配置为外网地址.

[source, bash]
.*1. Setup*
----
tmsh create ltm snat internet_access origins add { 10.1.20.0/24 } translation 10.1.10.100
----

[source, bash]
.*2. Test access external http service*
----
curl http://10.1.10.20/
----

[source, bash]
.*3. Clean up*
----
tmsh delete ltm snat internet_access
----

== 用例

[cols="2,5a"]
|===
|Name |Description

|SSH 到内网
|需要在外部网络穿透 SSH 连接到内部某台服务器

[source, bash]
----
// create nat
create ltm nat ssh_nat originating-address 10.1.20.14 translation-address 10.1.10.100 

// ssh
ssh root@10.1.10.100

// clean up
delete ltm nat ssh_nat 
----

|===

== 组网架构

=== 负载均衡设备组网有什么特殊之处

负载均衡设备属于网络设备，处于应用的入口，负责将网络负载分发到不同的应用，那么负载均衡设备组网和传统网络设备有什么不同？传统网络设备如路由器负责 OSI 3 层基于 IP 的转发，交换机设备负责 OSI 2 层基于链路或广播域的转发，分工明确，在传统的网络设计中，基本上都是按照交换和路由的原理来进行设计的。

在交换和路由的设计中，一个非常关键点就是都是基于数据包来进行转发的。在基于包交换的结构中，由于不用考虑连接，因此数据流量可以采用不对称的流向方式，比如在 OSPF、BGP 的环境下，同一个连接的往返数据包，甚至一个方向的数据包都可能通 过不同的链路进行传输。而所有控制数据包流向的依据都是按照 IP 包头中所包含的源 IP 地 址和目的 IP 地址进行转发。在这种情况下，完全不需要考虑连接的完整性。

而负载均衡设备是将网络负载转发向应用，所有的转发原则都是基于 OSI 4 层以上的信息来进行转发。最基本的就是按照连接来进行处理的。因此，在进行网络设计的时候，和传统的网络结构有所不同。在应用负载均衡的网络架构中，所有的处理都至少是基于四层信息，也就是除了源 IP 地址和目的地址之外，还要有源端口和目的端口参与转发判断。这样，就和 NAT 等基础处 理一样，同一个 connection 的往返数据流通常是需要都通过同一台设备。这样，在每台负载均衡设备上都能看到完整的数据流。另外，在进行一些七层处理的时候，数据流的往返通过同一 台设备也是属于必要条件之一。


=== 单臂接入模式

单臂模式是一种古老的接入模式，最初单臂模式的出现是因为负载均衡的性能不足造成的。在四层负载均衡出现的初期，所有的设备都是基于服务器结构的。四层负载均衡基本上是通过安装在服务器上的软件处理，在早期的 CPU 处理能力不足的情况下，负责均衡无法提供高带宽的吞吐能力，因此采用负载均衡只是提供用户请求的分配，而让真实服务器的回应都通过二/三层交换机直接回应给客户端。在大部分的 应用情况下，服务器的回应数据流量要远远大于客户的请求数据流量，因此，在这种情况下， 可以通过性能较差的负载均衡处理非常大的网络吞吐。

单臂模式为典型的基于服务器架构的负载均衡部署架构这些设备都提供较少的端口(2-6 个)。而采用单臂接入模式可以节省对负载均衡的端口使用量。因此， 在此类设备的部署结构中，会主要采用单臂模式接入。如下图，单臂接入模式下的网络结构，所谓单臂模式，就是指在上只配置一个 Vlan，使用一个端口(或者 Trunk 端 口)连接到网络中，所有的处理均在这一个 Vlan 中进行。

image:img/ltm-single-vlan.png[]

一句话总结，单笔模式，同一 VLAN，只处理请求，不处理返回。

如下图为单臂源地址替换接入典型主备高可用架构架构设计，

image:img/ltm-single-vlan-cluster.png[]

* 两台设备互为主备，主备之间有两条链路，分别进行网络同步和串口心跳
* 负载均衡设备和核心交换之间通过 Trunk 聚合链路
* 负载均衡设备和服务器处于同一个 VLAN，网关均为核心交换设备 

在单臂接入的网络结构下，存在有几中种数据流向或者是系统的配置模式。

==== 源地址替换模式

如下图为源地址替换模式数据访问流程示意，源地址替换模式是对已经上线系统结构变化最小的一种，在源地址替换模式下的设计要点主要有以下几点:

* 负载均衡只需要配置一个 Vlan，一个 interface 地址，虚拟服务的地址和服务器在同一个网段上。
* 在负载均衡上配置源地址 SNAT，使用户请求在发往服务器的时候，源地址均被替换为负载均衡的源地址。
* 所有服务器看到的数据请求的源地址均为负载均衡的源地址，而不是真正的客户端地址。

image;img/ltm-single-lan-source-replace.png[]


源地址替换模式的数据流处理流程如下:

1. 客户端发送请求到负载均衡上的虚拟服务器地址和端口，此时数据包的基本信息如下: Source IP:`192.168.0.1`，Source Port:`6787`，Destination IP:`192.168.1.1`，Destination Port:`80`
2. 核心交换机将请求转发到虚拟服务器，虚拟服务器对接收到的数据包进行修改，替换源 IP 为负载均衡设备上的 NAT 地址 `192.168.1.253`，源端口替换为一个随机的源端口，同时修改目的地址和目的端口为服务器的网卡地址 `192.168.1.11` 和应用侦听端口 `80`
3. 负载均衡将请求转发给服务器，此时数据包的基本信息如下: Source IP:`192.168.1.253`，Source Port:`8888`，Destination IP:`192.168.1.11`，Destination Port:`80`
4. 服务器处理完请求后将结果返回给负载均衡。此时数据包的基本信息如下: Source IP:`192.168.1.11`，Source Port:`80`，Destination IP:`192.168.1.253`，Destination Port:`8888`。负载均衡接收到数据包后对数据包进行修改，源IP为`192.168.1.1`，源端口为 `8888`，目的地IP 为`192.168.0.1`，目的地端口为`6768`
5. 负载均衡将数据包返回给核心交换设备，此时数据包的基本信息如下: Source IP:`192.168.1.1`，Source Port:`80`，Destination IP:`192.168.0.1`，Destination Port:`6768`
6. 核心交换设备将数据包返回给客户端

NOTE: 这种架构的缺点是服务器不知道客户端的地址，只有HTTP协议的时候，可以通过将源地址插入到客户端请求的HTTP Header里，然后在服务器上通过读取这个Header，获得客户端的真实源IP地址。
